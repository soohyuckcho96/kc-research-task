{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# fixed abstract, N; variation in tags\n",
    "KW: deep learning; DL; natural language processing; nlp; deep generative modeling; summarize; model(s); different application domain;\n",
    "\n",
    "All: deep learning methods possess many processing; have; results; domains; deep learning; natural; nlp; presents; brief; work considers most; many deep learning models; text; forward; past; explored; different\n",
    "P = 6 / 7; R = 3 / 8; F = 12 / 23\n",
    "\n",
    "N: representation; data; domains; learning model designs; language processing; learning models; generation models\n",
    "P = 2 / 3; R = 2 / 7; F = 2 / 5\n",
    "\n",
    "NV: processing layers; domains; designs; architectures have; survey presents; work considers; learning models; have been; have been explored; nlp\n",
    "P = 2 / 3; R = 1 / 5; F = 4 / 13\n",
    "\n",
    "NJ: deep learning; representation; results; domains; designs; natural; processing; brief description; many deep learning models; text; understanding; past\n",
    "P = 5 / 6; R = 5 / 12; F = 5 / 9"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# fixed abstarct, tag; variation in N\n",
    "KW: deep learning; DL; natural language processing; nlp; deep generative modeling; summarize; model(s); different application domain;\n",
    "\n",
    "2: deep learning; representation; results; domains; designs; natural; processing; brief description; many deep learning models; text; understanding; past\n",
    "P = 5 / 6; R = 5 / 12; F = 5 / 9\n",
    "\n",
    "3: deep learning; stratified; domains; deep learning model designs; language; nlp; brief description; papers; many deep learning models; past; generation models\n",
    "P = 6 / 7; R = 6 / 11; F = 2 / 3\n",
    "\n",
    "5: deep learning; layers; domains; architectures; nlp; brief; modeling; work; many deep learning models; present; future; text generation models\n",
    "P = 6 / 7; R = 1 / 2; F = 12 / 19\n",
    "\n",
    "10: deep learning; stratified representation; several domains; designs; architectures; context; nlp; survey; many deep learning models; text generation models\n",
    "P = 5 / 6; R = 1 / 2; F = 5 / 8\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# fixed N, tag; variation in abstract\n",
    "\n",
    "1: https://www.sciencedirect.com/science/article/pii/S1319157820303360?via%3Dihub\n",
    "\n",
    "KW: deep learning; DL; natural language processing; nlp; deep generative modeling; summarize; model(s); different application domain;\n",
    "\n",
    "S: deep learning; representation; results; domains; designs; natural; processing; brief description; many deep learning models; text; understanding; past\n",
    "P = 5 / 6; R = 5 / 12; F = 5 / 9\n",
    "\n",
    "2: https://link.springer.com/article/10.1023/A:1015531813214\n",
    "\n",
    "KW: linear constraints; linear diophantine equations; minimal generating sets; nonstrict inequations; set of natural numbers; strict inequations; upper bounds\n",
    "\n",
    "S: linear; equations; bounds; minimal; solutions; algorithms; systems\n",
    "P = 3 / 4; R = 1 / 2; F = 3 / 5\n",
    "\n",
    "3: https://www.aclweb.org/anthology/W04-3252.pdf\n",
    "\n",
    "KW: textrank; graph-based ranking model; text processing; natural language application; keyword; sentence; extraction\n",
    "\n",
    "S: model; text; natural; methods; keyword; sentence\n",
    "P = 5 / 6; R = 5 / 6; F = 5 / 6\n",
    "\n",
    "4: https://arxiv.org/abs/1911.03705\n",
    "\n",
    "KW: commonsense; realistically plausible sentences; contrained text generation; commongen; coherent sentence; relational reasoning; compositional generalization\n",
    "\n",
    "S: pre-trained language models; performance; several commonsense-reasoning benchmark; plausible sentences; text generation task; ability; generative commonsense; e.g.; frisbee; concept-sets; state-of-the-art text generation models; such\n",
    "P = 5 / 6; R = 5 / 12; F = 5 / 9\n",
    "\n",
    "5: https://www.aclweb.org/anthology/W11-1608.pdf\n",
    "\n",
    "KW: framework; abstractive summarization; abstract representation; information items; sematic analysis; automatic summrization;\n",
    "\n",
    "S: framework; abstractive summarization; abstract representation; source documents; information items; element; coherent information; previous abstractive summarization\n",
    "P = 5 / 6; R = 5 / 8; F = 5 / 7\n",
    "\n",
    "AVG: P = 0.82; R = 0.56; F = 0.65"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
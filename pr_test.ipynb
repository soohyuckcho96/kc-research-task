{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [(1, 'deep', 'JJ'), (2, 'learning', 'NN'), (3, 'methods', 'NNS'), (5, 'many', 'JJ'), (7, 'layers', 'NNS'), (11, 'stratified', 'JJ'), (12, 'representation', 'NN'), (14, 'data', 'NNS'), (18, 'state-of-art', 'JJ'), (19, 'results', 'NNS'), (21, 'several', 'JJ'), (22, 'domains', 'NNS'), (26, 'deep', 'JJ'), (27, 'learning', 'NN'), (28, 'model', 'NN'), (29, 'designs', 'NNS'), (31, 'architectures', 'NNS'), (36, 'context', 'NN'), (38, 'natural', 'JJ'), (39, 'language', 'NN'), (40, 'processing', 'NN'), (42, 'nlp', 'JJ'), (46, 'survey', 'NN'), (49, 'brief', 'JJ'), (50, 'description', 'NN'), (53, 'advances', 'NNS'), (59, 'area', 'NN'), (61, 'deep', 'JJ'), (62, 'generative', 'JJ'), (63, 'modeling', 'NN'), (66, 'work', 'NN'), (68, 'most', 'JJS'), (71, 'papers', 'NNS'), (74, 'onwards', 'NNS'), (78, 'paper', 'NN'), (82, 'many', 'JJ'), (83, 'deep', 'JJ'), (84, 'learning', 'NN'), (85, 'models', 'NNS'), (92, 'generation', 'NN'), (94, 'text', 'NN'), (100, 'various', 'JJ'), (101, 'models', 'NNS'), (107, 'detailed', 'JJ'), (108, 'understanding', 'NN'), (110, 'past', 'JJ'), (112, 'present', 'JJ'), (115, 'future', 'NN'), (117, 'text', 'JJ'), \n",
    "(118, 'generation', 'NN'), (119, 'models', 'NNS'), (121, 'deep', 'JJ'), (122, 'learning', 'NN'), (126, 'dl', 'JJ'), (127, 'approaches', 'NNS'), (135, 'different', 'JJ'), (136, 'application', 'NN'), (137, 'domains', 'NNS'), (139, 'nlp', 'NN'), (144, 'survey', 'NN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRGraph(object):\n",
    "    def __init__(self, filtered_tokens, w, k) -> None:\n",
    "        self.total_cnt = len(filtered_tokens)\n",
    "        words = [t[1] for t in filtered_tokens]\n",
    "        unique_words = list(Counter(words))\n",
    "        self.unique_cnt = len(unique_words)\n",
    "        self.conversion = {unique_words[i] : i for i in range(len(unique_words))}\n",
    "        # self.V = {self.conversion[v] : 1 / self.unique_cnt for v in unique_words}\n",
    "        self.S = [1 / self.unique_cnt for i in range(self.unique_cnt)]\n",
    "        self.E = {self.conversion[v] : [] for v in unique_words}\n",
    "        self.M = [[0 for _ in range(self.unique_cnt)] for _ in range(self.unique_cnt)]\n",
    "        self.alpha = 0.85\n",
    "        self.threshold = 0.001\n",
    "\n",
    "        for i in range(self.total_cnt):\n",
    "            token = filtered_tokens[i]\n",
    "            for j in range(w):\n",
    "                if i + j + 1 >= self.total_cnt:\n",
    "                    break\n",
    "                else:\n",
    "                    next_token = filtered_tokens[i + j + 1]\n",
    "                    if token[0] + w <= next_token[0]:\n",
    "                        break\n",
    "                    else:\n",
    "                        idx = self.conversion[token[1]]\n",
    "                        next_idx = self.conversion[next_token[1]]\n",
    "                        if next_idx not in self.E[idx]:\n",
    "                            self.E[idx].append(next_idx)\n",
    "                            self.E[next_idx].append(idx)\n",
    "                        self.M[idx][next_idx] += 1\n",
    "                        self.M[next_idx][idx] += 1\n",
    "        \n",
    "        self.M_tilde = [[0 for j in range(self.unique_cnt)] for i in range(self.unique_cnt)]\n",
    "        for i in range(self.unique_cnt):\n",
    "            row_sum = sum(self.M[i])\n",
    "            if row_sum != 0:\n",
    "                for j in range(self.unique_cnt):\n",
    "                    self.M_tilde[i][j] = self.M[i][j] / row_sum\n",
    "        \n",
    "        self.p_tilde = [0 for i in range(self.unique_cnt)]\n",
    "        for i in range(self.total_cnt):\n",
    "            token = filtered_tokens[i]\n",
    "            idx = self.conversion[token[1]]\n",
    "            self.p_tilde[idx] += 1 / token[0]\n",
    "        row_sum = sum(self.p_tilde)\n",
    "        for i in range(self.unique_cnt):\n",
    "            self.p_tilde[i] /= row_sum\n",
    "\n",
    "        self.conversion = {val : key for key, val in self.conversion.items()}\n",
    "    \n",
    "    def score_of(self, i):\n",
    "        temp = 0\n",
    "        for j in self.E[i]:\n",
    "            # temp += self.M_tilde[i][j] / sum(self.M[j])\n",
    "            temp += self.M[i][j] / sum(self.M[j])\n",
    "        return (1 - self.alpha) * self.p_tilde[i] + self.alpha * temp * self.S[i]\n",
    "\n",
    "    def calculate_positionrank(self):\n",
    "        flags = [False for i in range(self.unique_cnt)]\n",
    "        i = 0\n",
    "        iter_cnt = 0\n",
    "        while not all(flags) and iter_cnt < 100:\n",
    "            prev_score = self.S[i]\n",
    "            curr_score = self.score_of(i)\n",
    "            self.S[i] = curr_score\n",
    "            if abs(prev_score - curr_score) < self.threshold:\n",
    "                flags[i] = True\n",
    "            i = (i + 1) % self.unique_cnt\n",
    "            if i == 0:\n",
    "                iter_cnt += 1\n",
    "        return iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = PRGraph(filtered_tokens, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60 45\n"
     ]
    }
   ],
   "source": [
    "print(graph.total_cnt, graph.unique_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.M_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.p_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "iter_cnt = graph.calculate_positionrank()\n",
    "iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'deep': 3.1515487090927914e+23,\n",
       " 'learning': 2.407961350946923e+31,\n",
       " 'methods': 0.016863427251819472,\n",
       " 'many': 0.01098812499709402,\n",
       " 'layers': 0.006349596587674883,\n",
       " 'stratified': 0.026937682080673098,\n",
       " 'representation': 0.024692875402610955,\n",
       " 'data': 0.0031747982938374413,\n",
       " 'state-of-art': 0.016461917583049795,\n",
       " 'results': 0.015595500970464412,\n",
       " 'several': 0.0036809255580723954,\n",
       " 'domains': 1093563589.1132123,\n",
       " 'model': 0.053722387394820666,\n",
       " 'designs': 0.0026654978179144933,\n",
       " 'architectures': 0.0014337798746362638,\n",
       " 'context': 0.0012346437809367828,\n",
       " 'natural': 0.002034195703145271,\n",
       " 'language': 2.644760922593623e+21,\n",
       " 'processing': 0.001932485917988008,\n",
       " 'nlp': 0.0013780299548790812,\n",
       " 'survey': 0.0012749039042281997,\n",
       " 'brief': 0.006047236260339756,\n",
       " 'description': 0.0059262915740115095,\n",
       " 'advances': 0.0008386259644098902,\n",
       " 'area': 0.0007533419680292233,\n",
       " 'generative': 0.05839409245583255,\n",
       " 'modeling': 0.0012269751860241318,\n",
       " 'work': 0.0006734420623291543,\n",
       " 'most': 0.000653634942848885,\n",
       " 'papers': 0.0006260165649820307,\n",
       " 'onwards': 0.0006006375150503268,\n",
       " 'paper': 0.0005698355912015921,\n",
       " 'models': 8128359056204.276,\n",
       " 'generation': 7819.944143761324,\n",
       " 'text': 0.0014830133795070725,\n",
       " 'various': 0.0006201931550752211,\n",
       " 'detailed': 0.002769296163592911,\n",
       " 'understanding': 0.002743654550447861,\n",
       " 'past': 0.0004040652373974925,\n",
       " 'present': 0.00039684978672968016,\n",
       " 'future': 0.0003864971835976016,\n",
       " 'dl': 0.002351704178087806,\n",
       " 'approaches': 0.002333186837661346,\n",
       " 'different': 0.0005725884201445949,\n",
       " 'application': 832591432.8793393}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "kp_score = {}\n",
    "for i in range(graph.unique_cnt):\n",
    "    kp_score[graph.conversion[i]] = graph.S[i]\n",
    "kp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_grams(filtered_tokens, kp_score):\n",
    "    kw = {}\n",
    "    i = 0\n",
    "    while i < len(filtered_tokens):\n",
    "        token = filtered_tokens[i]\n",
    "        curr_idx = token[0]\n",
    "        curr_word = token[1]\n",
    "        curr_score = kp_score[curr_word]\n",
    "        # flag = True\n",
    "        j = i + 1\n",
    "        # while flag and j < len(filtered_tokens) and j < i + 3:\n",
    "        while j < len(filtered_tokens) and j < i + 3:\n",
    "            next_token = filtered_tokens[j]\n",
    "            next_idx = next_token[0]\n",
    "            if curr_idx + 1 != next_idx:\n",
    "                # flag = False\n",
    "                break\n",
    "            else:\n",
    "                curr_idx = next_idx\n",
    "                curr_word += ' ' + next_token[1]\n",
    "                curr_score += kp_score[next_token[1]]\n",
    "                j += 1\n",
    "        i = j\n",
    "        # i += 1\n",
    "        if curr_word not in kw:\n",
    "            kw[curr_word] = curr_score\n",
    "    kw = sorted(kw.items(), key=lambda x : x[1], reverse=True)\n",
    "    return kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('deep learning methods', 2.4079613824624103e+31),\n",
       " ('deep learning model', 2.4079613824624103e+31),\n",
       " ('many deep learning', 2.4079613824624103e+31),\n",
       " ('deep learning', 2.4079613824624103e+31),\n",
       " ('deep generative modeling', 3.1515487090927914e+23),\n",
       " ('natural language processing', 2.644760922593623e+21),\n",
       " ('text generation models', 8128359064024.222),\n",
       " ('various models', 8128359056204.277),\n",
       " ('models', 8128359056204.276),\n",
       " ('different application domains', 1926155021.9931242),\n",
       " ('several domains', 1093563589.1168933),\n",
       " ('generation', 7819.944143761324),\n",
       " ('stratified representation', 0.05163055748328405),\n",
       " ('state-of-art results', 0.03205741855351421),\n",
       " ('brief description', 0.011973527834351266),\n",
       " ('many', 0.01098812499709402),\n",
       " ('layers', 0.006349596587674883),\n",
       " ('detailed understanding', 0.005512950714040772),\n",
       " ('dl approaches', 0.004684891015749152),\n",
       " ('data', 0.0031747982938374413),\n",
       " ('designs', 0.0026654978179144933),\n",
       " ('text', 0.0014830133795070725),\n",
       " ('architectures', 0.0014337798746362638),\n",
       " ('nlp', 0.0013780299548790812),\n",
       " ('survey', 0.0012749039042281997),\n",
       " ('context', 0.0012346437809367828),\n",
       " ('advances', 0.0008386259644098902),\n",
       " ('area', 0.0007533419680292233),\n",
       " ('work', 0.0006734420623291543),\n",
       " ('most', 0.000653634942848885),\n",
       " ('papers', 0.0006260165649820307),\n",
       " ('onwards', 0.0006006375150503268),\n",
       " ('paper', 0.0005698355912015921),\n",
       " ('past', 0.0004040652373974925),\n",
       " ('present', 0.00039684978672968016),\n",
       " ('future', 0.0003864971835976016)]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "kw = get_n_grams(filtered_tokens, kp_score)\n",
    "kw = sorted(kw.items(), key=lambda x : x[1], reverse=True)\n",
    "kw"
   ]
  }
 ]
}
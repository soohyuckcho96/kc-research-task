{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [(3, 'new', 'JJ'), (5, 'ambitious', 'JJ'), (6, 'framework', 'NN'), (8, 'abstractive', 'JJ'), (9, 'summarization', 'NN'), (16, 'content', 'NN'), (19, 'summary', 'JJ'), (22, 'sentences', 'NNS'), (27, 'abstract', 'JJ'), (28, 'representation', 'NN'), (31, \n",
    "'source', 'NN'), (32, 'documents', 'NNS'), (35, 'abstract', 'JJ'), (36, 'representation', 'NN'), (37, 'relies', 'NNS'), (40, 'concept', 'NN'), (42, 'information', 'NN'), (43, 'items', 'NNS'), (45, 'init', 'NN'), (53, 'smallest', 'JJS'), (54, 'element', 'NN'), (56, 'coherent', 'JJ'), (57, 'information', 'NN'), (60, 'text', 'NN'), (63, \n",
    "'sentence', 'NN'), (66, 'framework', 'NN'), (67, 'differs', 'NNS'), (69, 'previous', 'JJ'), (70, 'abstractive', 'JJ'), (71, 'summarization', 'NN'), (72, 'models', 'NNS'), (76, 'semantic', 'JJ'), (77, 'analysis', 'NN'), (80, 'text', 'NN'), (85, 'first', 'JJ'), (86, 'attempt', 'NN'), (91, 'system', 'NN'), (94, 'framework', 'NN'), (98, 'evaluation', 'NN'), (99, 'results', 'NNS'), (103, 'tac', 'JJ'), (108, 'related', 'JJ'), (109, 'work', 'NN'), (118, 'automatic', 'JJ'), (119, 'summarization', 'NN'), (120, 'domain', 'NN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOUN_GROUP = ['NN', 'NNS', 'NNP', 'NNPS'] # 4\n",
    "PRONOUN_GROUP = ['PRP', 'PRP$', 'WP', 'WP$'] # 4\n",
    "VERB_GROUP = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'] # 6\n",
    "ADJECTIVE_GROUP = ['JJ', 'JJR', 'JJS'] # 3\n",
    "ADVERB_GROUP = ['RB', 'RBR', 'RBS', 'WRB']\n",
    "PREPOSITION_GROUP = ['IN']\n",
    "CONJUNCTION_GROUP = ['CC', 'IN']\n",
    "INTERJECTION_GROUP = ['UH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalGraph(object):\n",
    "    def __init__(self, filtered_tokens, N):\n",
    "        self.total_cnt = len(filtered_tokens)\n",
    "        words = [t[1] for t in filtered_tokens]\n",
    "        unique_words = list(Counter(words))\n",
    "        self.unique_cnt = len(unique_words)\n",
    "        self.T = self.unique_cnt // 3\n",
    "        self.conversion = {unique_words[i] : i for i in range(len(unique_words))}\n",
    "        self.V = {self.conversion[v] : 1 for v in unique_words}\n",
    "        self.E = {self.conversion[v] : [] for v in unique_words}\n",
    "        self.jump_factor = 0.85\n",
    "        self.threshold = 0.0001\n",
    "\n",
    "        for i in range(self.total_cnt):\n",
    "            token = filtered_tokens[i]\n",
    "            for j in range(N):\n",
    "                if i + j + 1 >= self.total_cnt:\n",
    "                    break\n",
    "                else:\n",
    "                    next_token = filtered_tokens[i + j + 1]\n",
    "                    if token[0] + N < next_token[0]:\n",
    "                        break\n",
    "                    else:\n",
    "                        idx = self.conversion[token[1]]\n",
    "                        next_idx = self.conversion[next_token[1]]\n",
    "                        if next_idx not in self.E[idx]:\n",
    "                            self.E[idx].append(next_idx)\n",
    "                            self.E[next_idx].append(idx)\n",
    "\n",
    "        self.conversion = {v : k for k, v in self.conversion.items()}\n",
    "        \n",
    "    def score_of(self, word):\n",
    "        neighbor_list = self.E[word]\n",
    "        temp = 0\n",
    "        for neighbor in neighbor_list:\n",
    "            temp += self.V[neighbor] / len(self.E[neighbor])\n",
    "        return (1 - self.jump_factor) + self.jump_factor * temp\n",
    "\n",
    "    def calculate_textrank(self):\n",
    "        flags = [False for i in range(self.unique_cnt)]\n",
    "        i = 0\n",
    "        iter_cnt = 0\n",
    "        while not all(flags):\n",
    "            prev_score = self.V[i]\n",
    "            curr_score = self.score_of(i)\n",
    "            self.V[i] = curr_score\n",
    "            if abs(prev_score - curr_score) < self.threshold:\n",
    "                flags[i] = True\n",
    "            i = (i + 1) % self.unique_cnt\n",
    "            if i == 0:\n",
    "                iter_cnt += 1\n",
    "        return iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = LexicalGraph(tokens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46 37 12\n"
     ]
    }
   ],
   "source": [
    "print(graph.total_cnt, graph.unique_cnt, graph.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "iter_cnt = graph.calculate_textrank()\n",
    "iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(4, 1.7234395460349212), (14, 1.6397522169176293), (3, 1.4023515584247277), (2, 1.195749513261997), (18, 1.175871169409576), (15, 1.1617901548644278), (19, 1.1143417084590648), (23, 1.0786637438486126), (8, 1.0), (9, 1.0), (10, 1.0), (11, 1.0), (12, 1.0), (25, 1.0), (26, 1.0), (27, 1.0), (28, 1.0), (30, 1.0), (31, 1.0), (33, 1.0), (34, 1.0), (1, 0.9649109431072667), (22, 0.7944581516003275), (35, 0.7704598904905071), (36, 0.7704468348656691), (24, 0.7410190294184734), (17, 0.6497407581380162), (16, 0.6437608158173818), (13, 0.6145922418437773), (0, 0.5601112541042375), (5, 0.15000000000000002), (6, 0.15000000000000002), (7, 0.15000000000000002), (20, 0.15000000000000002), (21, 0.15000000000000002), (29, 0.15000000000000002), (32, 0.15000000000000002)]\n"
     ]
    }
   ],
   "source": [
    "rev_sorted_scores = sorted(graph.V.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['summarization', 'information', 'abstractive', 'framework', 'element', 'items', 'coherent', 'previous', 'abstract', 'representation', 'source', 'documents'] [1.7234395460349212, 1.6397522169176293, 1.4023515584247277, 1.195749513261997, 1.175871169409576, 1.1617901548644278, 1.1143417084590648, 1.0786637438486126, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "potential_keywords = []\n",
    "potential_keywords_score = []\n",
    "cur_score = math.inf\n",
    "for i in range(graph.T):\n",
    "    cur_score = rev_sorted_scores[i][1]\n",
    "    word = graph.conversion[rev_sorted_scores[i][0]]\n",
    "    potential_keywords.append(word)\n",
    "    potential_keywords_score.append(cur_score)\n",
    "print(potential_keywords, potential_keywords_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_2 = ['summarization', 'information', 'abstractive', 'framework', 'element', 'items', 'coherent', 'previous', 'abstract', 'representation', 'source', 'documents']\n",
    "n_3 = ['framework', 'information', 'summarization', 'abstractive', 'summary', 'previous', 'text', 'abstract', 'representation', 'relies', 'element', 'coherent']\n",
    "n_4 = ['framework', 'summarization', 'information', 'summary', 'abstractive', 'representation', 'text', 'differs', 'previous', 'abstract', 'concept', 'coherent']\n",
    "n_5 = ['framework', 'summarization', 'information', 'abstract', 'abstractive', 'text', 'concept', 'models', 'differs', 'representation', 'relies', 'previous']\n",
    "n_6 = ['framework', 'summarization', 'information', 'text', 'abstractive', 'representation', 'relies', 'models', 'abstract', 'tac', 'concept', 'differs']\n",
    "n_7 = ['summarization', 'framework', 'text', 'information', 'abstractive', 'representation', 'abstract', 'relies', 'models', 'sentence', 'differs', 'tac']\n",
    "n_8 = ['summarization', 'framework', 'text', 'information', 'abstractive', 'representation', 'abstract', 'relies', 'models', 'sentence', 'differs', 'tac']\n",
    "n_9 = ['framework', 'summarization', 'text', 'representation', 'information', 'abstract', 'abstractive', 'sentence', 'previous', 'models', 'relies', 'concept']\n",
    "n_10 = ['framework', 'summarization', 'text', 'information', 'abstractive', 'abstract', 'representation', 'sentence', 'semantic', 'differs', 'analysis', 'previous'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_word_keyword(potential_keywords, filtered_tokens):\n",
    "    relation = [t for t in filtered_tokens if t[1] in potential_keywords]\n",
    "    keywords = []\n",
    "    i = 0\n",
    "    while i < len(relation):\n",
    "        idx = relation[i][0]\n",
    "        keyword = relation[i][1]\n",
    "        flag = True\n",
    "        j = i + 1\n",
    "        while flag and j < len(relation):\n",
    "            next_idx = relation[j][0]\n",
    "            if next_idx == idx + 1:\n",
    "                keyword += ' ' + relation[j][1]\n",
    "                idx = next_idx\n",
    "                j += 1\n",
    "            else:\n",
    "                flag = False\n",
    "        i = j\n",
    "        if keyword not in keywords:\n",
    "            print (keyword)\n",
    "            keywords.append(keyword)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "framework\nabstractive summarization\nabstract representation\nsource documents\ninformation items\nelement\ncoherent information\nprevious abstractive summarization\nsummarization\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['framework',\n",
       " 'abstractive summarization',\n",
       " 'abstract representation',\n",
       " 'source documents',\n",
       " 'information items',\n",
       " 'element',\n",
       " 'coherent information',\n",
       " 'previous abstractive summarization',\n",
       " 'summarization']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "final_keywords = combine_multi_word_keyword(potential_keywords, tokens)\n",
    "final_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [(3, 'new', 'JJ'), (5, 'ambitious', 'JJ'), (6, 'framework', 'NN'), (8, 'abstractive', 'JJ'), (9, 'summarization', 'NN'), (16, 'content', 'NN'), (19, 'summary', 'JJ'), (22, 'sentences', 'NNS'), (27, 'abstract', 'JJ'), (28, 'representation', 'NN'), (31, \n",
    "'source', 'NN'), (32, 'documents', 'NNS'), (35, 'abstract', 'JJ'), (36, 'representation', 'NN'), (37, 'relies', 'NNS'), (40, 'concept', 'NN'), (42, 'information', 'NN'), (43, 'items', 'NNS'), (45, 'init', 'NN'), (53, 'smallest', 'JJS'), (54, 'element', 'NN'), (56, 'coherent', 'JJ'), (57, 'information', 'NN'), (60, 'text', 'NN'), (63, \n",
    "'sentence', 'NN'), (66, 'framework', 'NN'), (67, 'differs', 'NNS'), (69, 'previous', 'JJ'), (70, 'abstractive', 'JJ'), (71, 'summarization', 'NN'), (72, 'models', 'NNS'), (76, 'semantic', 'JJ'), (77, 'analysis', 'NN'), (80, 'text', 'NN'), (85, 'first', 'JJ'), (86, 'attempt', 'NN'), (91, 'system', 'NN'), (94, 'framework', 'NN'), (98, 'evaluation', 'NN'), (99, 'results', 'NNS'), (103, 'tac', 'JJ'), (108, 'related', 'JJ'), (109, 'work', 'NN'), (118, 'automatic', 'JJ'), (119, 'summarization', 'NN'), (120, 'domain', 'NN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOUN_GROUP = ['NN', 'NNS', 'NNP', 'NNPS'] # 4\n",
    "PRONOUN_GROUP = ['PRP', 'PRP$', 'WP', 'WP$'] # 4\n",
    "VERB_GROUP = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'] # 6\n",
    "ADJECTIVE_GROUP = ['JJ', 'JJR', 'JJS'] # 3\n",
    "ADVERB_GROUP = ['RB', 'RBR', 'RBS', 'WRB']\n",
    "PREPOSITION_GROUP = ['IN']\n",
    "CONJUNCTION_GROUP = ['CC', 'IN']\n",
    "INTERJECTION_GROUP = ['UH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalGraph(object):\n",
    "    def __init__(self, filtered_tokens, N):\n",
    "        self.total_cnt = len(filtered_tokens)\n",
    "        words = [t[1] for t in filtered_tokens]\n",
    "        unique_words = list(Counter(words))\n",
    "        self.unique_cnt = len(unique_words)\n",
    "        self.T = self.unique_cnt // 3\n",
    "        self.conversion = {unique_words[i] : i for i in range(len(unique_words))}\n",
    "        self.V = {self.conversion[v] : 1 for v in unique_words}\n",
    "        self.E = {self.conversion[v] : [] for v in unique_words}\n",
    "        self.jump_factor = 0.85\n",
    "        self.threshold = 0.0001\n",
    "\n",
    "        for i in range(self.total_cnt):\n",
    "            token = filtered_tokens[i]\n",
    "            for j in range(N):\n",
    "                if i + j + 1 >= self.total_cnt:\n",
    "                    break\n",
    "                else:\n",
    "                    next_token = filtered_tokens[i + j + 1]\n",
    "                    if token[0] + N < next_token[0]:\n",
    "                        break\n",
    "                    else:\n",
    "                        idx = self.conversion[token[1]]\n",
    "                        next_idx = self.conversion[next_token[1]]\n",
    "                        if next_idx not in self.E[idx]:\n",
    "                            self.E[idx].append(next_idx)\n",
    "                            self.E[next_idx].append(idx)\n",
    "\n",
    "        self.conversion = {v : k for k, v in self.conversion.items()}\n",
    "        \n",
    "    def score_of(self, word):\n",
    "        neighbor_list = self.E[word]\n",
    "        temp = 0\n",
    "        for neighbor in neighbor_list:\n",
    "            temp += self.V[neighbor] / len(self.E[neighbor])\n",
    "        return (1 - self.jump_factor) + self.jump_factor * temp\n",
    "\n",
    "    def calculate_textrank(self):\n",
    "        flags = [False for i in range(self.unique_cnt)]\n",
    "        i = 0\n",
    "        iter_cnt = 0\n",
    "        while not all(flags):\n",
    "            prev_score = self.V[i]\n",
    "            curr_score = self.score_of(i)\n",
    "            self.V[i] = curr_score\n",
    "            if abs(prev_score - curr_score) < self.threshold:\n",
    "                flags[i] = True\n",
    "            i = (i + 1) % self.unique_cnt\n",
    "            if i == 0:\n",
    "                iter_cnt += 1\n",
    "        return iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = LexicalGraph(tokens, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46 37 12\n"
     ]
    }
   ],
   "source": [
    "print(graph.total_cnt, graph.unique_cnt, graph.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "iter_cnt = graph.calculate_textrank()\n",
    "iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sorted_scores = sorted(graph.V.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['framework', 'summarization', 'text', 'information', 'abstractive', 'abstract', 'representation', 'sentence', 'semantic', 'differs', 'analysis', 'previous'] [2.247585647834594, 1.973199437522402, 1.6770341972931995, 1.5709665931622898, 1.4016703053578334, 1.397996960688166, 1.3979912298362316, 1.2545314757647157, 1.1646661986353695, 1.138046728663634, 1.06273593103077, 1.0410729183333416]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "potential_keywords = []\n",
    "potential_keywords_score = []\n",
    "cur_score = math.inf\n",
    "for i in range(graph.T):\n",
    "    # if cur_score == rev_sorted_scores[i][1]:\n",
    "    #     break\n",
    "    # else:\n",
    "    cur_score = rev_sorted_scores[i][1]\n",
    "    word = graph.conversion[rev_sorted_scores[i][0]]\n",
    "    potential_keywords.append(word)\n",
    "    potential_keywords_score.append(cur_score)\n",
    "print(potential_keywords, potential_keywords_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_2 = ['summarization', 'information', 'abstractive', 'framework', 'element', 'items', 'coherent', 'previous', 'abstract', 'representation', 'source', 'documents']\n",
    "n_3 = ['framework', 'information', 'summarization', 'abstractive', 'summary', 'previous', 'text', 'abstract', 'representation', 'relies', 'element', 'coherent']\n",
    "n_4 = ['framework', 'summarization', 'information', 'summary', 'abstractive', 'representation', 'text', 'differs', 'previous', 'abstract', 'concept', 'coherent']\n",
    "n_5 = ['framework', 'summarization', 'information', 'abstract', 'abstractive', 'text', 'concept', 'models', 'differs', 'representation', 'relies', 'previous']\n",
    "n_6 = ['framework', 'summarization', 'information', 'text', 'abstractive', 'representation', 'relies', 'models', 'abstract', 'tac', 'concept', 'differs']\n",
    "n_7 = ['summarization', 'framework', 'text', 'information', 'abstractive', 'representation', 'abstract', 'relies', 'models', 'sentence', 'differs', 'tac']\n",
    "n_8 = ['summarization', 'framework', 'text', 'information', 'abstractive', 'representation', 'abstract', 'relies', 'models', 'sentence', 'differs', 'tac']\n",
    "n_9 = ['framework', 'summarization', 'text', 'representation', 'information', 'abstract', 'abstractive', 'sentence', 'previous', 'models', 'relies', 'concept']\n",
    "n_10 = ['framework', 'summarization', 'text', 'information', 'abstractive', 'abstract', 'representation', 'sentence', 'semantic', 'differs', 'analysis', 'previous'] "
   ]
  }
 ]
}
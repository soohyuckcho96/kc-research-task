{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "de98f24d936b54738f034aaefff25bd15934cd624d7ab7c984fdb966cd675040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_dict = {'deep learning methods': [2], 'layers': [6], 'stratified representation': [11], 'data': [13], 'state-of-art results': [18], 'several domains': [21], 'deep learning model designs': [28], 'architectures': [30], 'context': [35], 'natural language processing': [39], 'survey': [45, 143], 'brief description': [49], 'advances': [52], 'area': [58], 'deep generative modeling': [62], 'work': [65], 'papers': [70], 'onwards': [73], 'paper': [77], 'many deep learning models': [84], 'generation': [91], 'text': [93], 'various models': [100], 'detailed understanding': [107], 'future': [114], 'text generation models': [118], 'deep learning': [121], 'dl approaches': [126], 'different application domains': [136], 'nlp': [138]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_assign_dict = {'deep learning methods': 0, 'layers': 1, 'stratified representation': 2, 'data': 3, 'state-of-art results': 4, 'several domains': 5, 'deep learning model designs': 0, 'architectures': 6, 'context': 7, 'natural language processing': 8, 'survey': 9, 'brief description': 10, 'advances': 11, 'area': 12, 'deep generative modeling': 0, 'work': 13, 'papers': 14, 'onwards': 15, 'paper': 14, 'many deep learning models': 0, 'generation': 16, 'text': 17, 'various models': 18, 'detailed understanding': 19, 'future': 20, 'text generation models': 16, 'deep learning': 0, 'dl approaches': 0, 'different application domains': 5, 'nlp': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_occurence = {0: 'deep learning methods', 1: 'layers', 2: 'stratified representation', 3: 'data', 4: 'state-of-art results', 5: 'several domains', 6: 'architectures', 7: 'context', 8: 'natural language processing', 9: 'survey', 10: 'brief description', 11: 'advances', 12: 'area', 13: 'work', 14: 'papers', 15: 'onwards', 16: 'generation', 17: 'text', 18: 'various models', 19: 'detailed understanding', 20: 'future'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPGraph(object):\n",
    "    def __init__(self, offset_dict, topic_assign_dict, first_occurence):\n",
    "        self.unique_cnt = len(offset_dict)\n",
    "        unique_words = list(offset_dict.keys())\n",
    "        self.conversion = {unique_words[i] : i for i in range(self.unique_cnt)}\n",
    "        self.V = {self.conversion[v] : 1 for v in unique_words}\n",
    "        # self.E = {self.conversion[v] : [] for v in unique_words}\n",
    "        self.M = [[0 for _ in range(self.unique_cnt)] for _ in range(self.unique_cnt)]\n",
    "        self.alpha = 1.1\n",
    "        self.damping_factor = 0.85\n",
    "        self.threshold = 0.0001\n",
    "\n",
    "        for i in range(self.unique_cnt):\n",
    "            word_i = unique_words[i]\n",
    "            for j in range(i + 1, self.unique_cnt):\n",
    "                word_j = unique_words[j]\n",
    "                if topic_assign_dict[word_i] != topic_assign_dict[word_j]:\n",
    "                    weight = 0\n",
    "                    for p_i in offset_dict[word_i]:\n",
    "                        for p_j in offset_dict[word_j]:\n",
    "                            weight += 1 / abs(p_i - p_j)\n",
    "                    self.M[i][j] = weight\n",
    "                    self.M[j][i] = weight\n",
    "\n",
    "        for i in range(len(first_occurence)):\n",
    "            word_i = first_occurence[i]\n",
    "            i_idx = self.conversion[word_i]\n",
    "            for j in range(len(first_occurence)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                word_j = first_occurence[j]\n",
    "                j_idx = self.conversion[word_j]\n",
    "                p_i = offset_dict[word_i][0]\n",
    "                temp = 0\n",
    "                for k in range(self.unique_cnt):\n",
    "                    word_k = unique_words[k]\n",
    "                    if topic_assign_dict[word_j] == topic_assign_dict[word_k] and word_j != word_k:\n",
    "                        temp += self.M[k][i_idx]\n",
    "                self.M[i_idx][j_idx] += self.alpha * math.exp(1 / p_i) * temp\n",
    "\n",
    "    def score_of(self, i):\n",
    "        temp = 0\n",
    "        for j in range(self.unique_cnt):\n",
    "            if self.M[j][i] != 0:\n",
    "                temp += self.M[i][j] * self.V[j] / sum(self.M[j])\n",
    "        return (1 - self.damping_factor) + self.damping_factor * temp\n",
    "\n",
    "    def calculate_textrank(self):\n",
    "        flags = [False for _ in range(self.unique_cnt)]\n",
    "        i = 0\n",
    "        iter_cnt = 0\n",
    "        while not all(flags):\n",
    "            prev_score = self.V[i]\n",
    "            curr_score = self.score_of(i)\n",
    "            self.V[i] = curr_score\n",
    "            if abs(prev_score - curr_score) < self.threshold:\n",
    "                flags[i] = True\n",
    "            i = (i + 1) % self.unique_cnt\n",
    "            if i == 0:\n",
    "                iter_cnt += 1\n",
    "        return iter_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = MPGraph(offset_dict, topic_assign_dict, first_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "graph.calculate_textrank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 0.6724202483953781,\n",
       " 1: 0.9068562624901729,\n",
       " 2: 1.1123216424179656,\n",
       " 3: 1.136587426447237,\n",
       " 4: 1.0901468126508929,\n",
       " 5: 1.0935406566788792,\n",
       " 6: 0.9751455210065306,\n",
       " 7: 1.4860940737819077,\n",
       " 8: 1.128538492455347,\n",
       " 9: 1.0683461022604674,\n",
       " 10: 1.8988095118364878,\n",
       " 11: 1.1802607892883192,\n",
       " 12: 1.1747499099342509,\n",
       " 13: 1.2563963476700684,\n",
       " 14: 0.9641153392656773,\n",
       " 15: 1.4084980610922093,\n",
       " 16: 1.1398988463509747,\n",
       " 17: 1.37123628840477,\n",
       " 18: 0.8312199632199917,\n",
       " 19: 0.7480033088092131,\n",
       " 20: 1.2082857446192174,\n",
       " 21: 1.2246325930061746,\n",
       " 22: 0.9976856104063598,\n",
       " 23: 1.016571822447009,\n",
       " 24: 1.2611127791355243,\n",
       " 25: 0.9155663176671401,\n",
       " 26: 0.7429828393324167,\n",
       " 27: 0.6003374446952003,\n",
       " 28: 0.857240544239227,\n",
       " 29: 0.8605976638566009}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "graph.V"
   ]
  }
 ]
}